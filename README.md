# NestJS + OpenAI ChatGPT Starter

A NestJS starter project integrated with the **official OpenAI API** for building ChatGPT-powered applications.

![Patrick Star](https://media0.giphy.com/media/XdyyR97fGCELK/giphy.gif?cid=ecf05e47gt29de2jbwlhheibrr895r8qar1w8u40dz99psf8&rid=giphy.gif&ct=g)

## âœ¨ Features

- âœ… **Official OpenAI SDK** - Uses the maintained and reliable `openai` package
- âœ… **Environment Configuration** - Secure API key management with `@nestjs/config`
- âœ… **TypeScript Support** - Full type safety
- âœ… **Ready-to-use ChatGPT Service** - Pre-configured service for chat completions
- âœ… **REST API Endpoint** - Example POST endpoint to interact with ChatGPT

## ğŸš€ Quick Start

### 1. Installation

```bash
npm install
```

### 2. Environment Setup

Create a `.env` file in the root directory:

```bash
cp .env.example .env
```

Then add your OpenAI API key to `.env`:

```env
OPENAI_API_KEY=sk-your-actual-api-key-here
```

**Get your API key from:** [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)

### 3. Running the Application

```bash
# development mode
npm run start

# watch mode (recommended for development)
npm run start:dev

# production mode
npm run start:prod
```

The server will start on `http://localhost:3000`

## ğŸ“¡ API Usage

### Chat Endpoint

Send a POST request to `/chat` with a message:

```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello, ChatGPT!"}'
```

**Response:**

```json
{
  "success": true,
  "message": "Hello, ChatGPT!",
  "response": "Hello! How can I assist you today?"
}
```

### Example with JavaScript/Fetch

```javascript
fetch('http://localhost:3000/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'What is NestJS?'
  })
})
  .then(res => res.json())
  .then(data => console.log(data.response));
```

## ğŸ—ï¸ Project Structure

```
src/
â”œâ”€â”€ app.controller.ts      # Main controller with /chat endpoint
â”œâ”€â”€ app.module.ts          # Root module with ConfigModule
â”œâ”€â”€ app.service.ts         # App service
â”œâ”€â”€ chatgpt.service.ts     # ChatGPT service with OpenAI integration
â””â”€â”€ main.ts                # Application entry point
```

## ğŸ”§ Configuration

The `ChatGPTService` is configured with:

- **Model:** `gpt-3.5-turbo` (you can change to `gpt-4` or other models)
- **Max Tokens:** 500
- **Temperature:** 0.7

Modify these in `src/chatgpt.service.ts` as needed.

## ğŸ§ª Testing

```bash
# unit tests
npm run test

# e2e tests
npm run test:e2e

# test coverage
npm run test:cov
```

## ğŸ“ Why This Boilerplate?

The old `chatgpt` package (v3.x) had several issues:
- âŒ Used unofficial browser-based authentication
- âŒ Deprecated and unreliable
- âŒ CommonJS/ESM module conflicts
- âŒ No longer maintained

This starter uses the **official OpenAI SDK** which:
- âœ… Is actively maintained by OpenAI
- âœ… Supports all latest models (GPT-4, GPT-3.5-turbo, etc.)
- âœ… Has proper TypeScript support
- âœ… Uses official API keys (secure and reliable)

## ğŸ”’ Security Notes

- Never commit your `.env` file to version control
- Keep your OpenAI API key secret
- The `.env` file is already in `.gitignore`
- Use `.env.example` as a template for sharing

## ğŸ“š Documentation

- [NestJS Documentation](https://docs.nestjs.com/)
- [OpenAI API Documentation](https://platform.openai.com/docs/)
- [OpenAI Node.js SDK](https://github.com/openai/openai-node)

## ğŸ’¡ Tips

- Monitor your API usage at [platform.openai.com/usage](https://platform.openai.com/usage)
- Set usage limits to avoid unexpected charges
- Consider implementing rate limiting for production use
- Add error handling and retry logic for production applications

## ğŸ“„ License

This project is [MIT licensed](LICENSE).

---

If this boilerplate saved you time, please **leave a â­** on the repository!
